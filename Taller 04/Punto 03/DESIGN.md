# üèóÔ∏è Dise√±o y Arquitectura ‚Äì `punto_03.cpp`

Este documento describe la **arquitectura interna** del programa `punto_03`,
que implementa una RNA simple en C++ para clasificar n√∫meros 0‚Äì9 en 4 clases.

---

## 1. Objetivo del Sistema

- Leer n√∫meros en **binario** desde `digitos.txt`.
- Convertir cada l√≠nea a un entero \(n \in [0, 9]\).
- Construir un conjunto de entrenamiento \((X, Y)\).
- Entrenar una Red Neuronal **10‚Äë8‚Äë4** con backpropagation.
- Clasificar los n√∫meros y mostrar su clase:

  - `0`: par.
  - `1`: impar.
  - `2`: primo.
  - `3`: compuesto.

---

## 2. Arquitectura General

### Diagrama de Flujo Alto Nivel
```
digitos.txt (binario por l√≠nea)
‚îÇ
‚ñº
Preprocesamiento
(limpiar + bin‚Üíint)
‚îÇ
‚ñº
Dataset (X,Y)
X: one-hot d√≠gito 0-9
Y: vector clases (0-3)
‚îÇ
‚ñº
Red Neuronal 10-8-4
‚îÇ
‚ñº
Clasificaci√≥n y salida
```

---

## 3. Componentes Principales

Todo est√° implementado en un √∫nico archivo `punto_03.cpp`, organizado en bloques:

1. **Utilidades num√©ricas**
   - Inicializaci√≥n aleatoria de pesos.
   - Funci√≥n de activaci√≥n sigmoide y su derivada.

2. **Conversi√≥n y propiedades de n√∫meros**
   - `binario_a_int`: convierte un string de bits a entero.
   - `esPrimo`, `esCompuesto`: para etiquetar los datos.

3. **Codificaci√≥n de datos**
   - `encode_input(int)`: entero 0‚Äì9 ‚Üí vector one‚Äëhot de tama√±o 10.
   - `encode_target(int)`: entero 0‚Äì9 ‚Üí vector de tama√±o 4 con clases.

4. **Clase `NeuralNet`**
   - Representa una red 10‚Äë8‚Äë4:
     - 10 neuronas de entrada.
     - 8 neuronas ocultas.
     - 4 neuronas de salida.
   - M√©todos:
     - `forward`: propagaci√≥n hacia adelante.
     - `train_example`: una iteraci√≥n de backpropagation para un ejemplo.

5. **Entrada de datos**
   - `leer_digitos_binarios`: lee `digitos.txt`, limpia cada l√≠nea y convierte a enteros.

6. **Orquestaci√≥n (`main`)**
   - Construye el dataset `X`, `Y`.
   - Crea la red y la entrena.
   - Clasifica los datos y muestra resultados.

---

## 4. Dise√±o de Datos

### 4.1 Representaci√≥n de Entradas

Para un entero \(d \in \{0,1,\dots,9\}\):  encode_input(d) ‚Üí vector<double> tama√±o 10


Ejemplos:

- `d = 3` ‚Üí `[0,0,0,1,0,0,0,0,0,0]`
- `d = 7` ‚Üí `[0,0,0,0,0,0,0,1,0,0]`

Esta representaci√≥n **one‚Äëhot** hace que cada d√≠gito sea una base can√≥nica en \(\mathbb{R}^{10}\).

### 4.2 Representaci√≥n de Salidas

Las clases se codifican en un vector de tama√±o 4:

Orden: `[par, impar, primo, compuesto]`.

Ejemplos:

- `d = 2` (par y primo): `[1, 0, 1, 0]`.
- `d = 9` (impar y compuesto): `[0, 1, 0, 1]`.
- `d = 1` (impar, ni primo ni compuesto): `[0, 1, 0, 0]`.
- `d = 0` (par, ni primo ni compuesto): `[1, 0, 0, 0]`.

En la predicci√≥n se toma el √≠ndice con mayor activaci√≥n como **clase dominante**.

---

## 5. Clase `NeuralNet`

### 5.1 Atributos
int n_input, n_hidden, n_output;

// input -> hidden
std::vector<std::vector<double>> w_ih; // [hidden][input]
std::vector<double> b_h;

// hidden -> output
std::vector<std::vector<double>> w_ho; // [output][hidden]
std::vector<double> b_o;

// activaciones
std::vector<double> a_in; // tama√±o 10
std::vector<double> a_h; // tama√±o 8
std::vector<double> a_out; // tama√±o 4